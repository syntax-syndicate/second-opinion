{
  "model_priority": [
    {
      "platform": "grok",
      "model": "grok-4",
      "description": "xAI's most advanced model - cutting-edge reasoning and capabilities",
      "quality_score": 97
    },
    {
      "platform": "gemini",
      "model": "gemini-2.5-pro",
      "description": "Google's most powerful model - highest capability but slower",
      "quality_score": 96
    },
    {
      "platform": "gemini",
      "model": "gemini-2.5-flash",
      "description": "Google's latest flagship model - excellent balance of speed and capability",
      "quality_score": 95
    },
    {
      "platform": "openai",
      "model": "gpt-4.1",
      "description": "OpenAI's latest flagship model - top tier reasoning and knowledge",
      "quality_score": 94
    },
    {
      "platform": "gemini",
      "model": "gemini-2.5-flash-lite-preview-06-17",
      "description": "Google's optimized lightweight model - very fast with good quality",
      "quality_score": 92
    },
    {
      "platform": "gemini",
      "model": "gemini-2.5-pro",
      "description": "Google's most powerful model - highest capability but slower",
      "quality_score": 96
    },
    {
      "platform": "openrouter",
      "model": "anthropic/claude-3-5-sonnet-20241022",
      "description": "OpenRouter access to Claude 3.5 Sonnet - excellent balanced performance",
      "quality_score": 93
    },
    {
      "platform": "openrouter",
      "model": "openai/gpt-4-turbo",
      "description": "OpenRouter access to GPT-4 Turbo - powerful OpenAI model",
      "quality_score": 92
    },
    {
      "platform": "grok",
      "model": "grok-3",
      "description": "xAI's last-gen flagship model - meh",
      "quality_score": 91
    },
    {
      "platform": "claude",
      "model": "claude-4-sonnet-20250514",
      "description": "Anthropic's balanced model - great for general tasks",
      "quality_score": 90
    },
    {
      "platform": "openai",
      "model": "gpt-4o",
      "description": "OpenAI's multimodal powerhouse - excellent for vision and text",
      "quality_score": 89
    },
    {
      "platform": "deepseek",
      "model": "deepseek-chat",
      "description": "DeepSeek's fast general model - good performance and speed",
      "quality_score": 87
    },
    {
      "platform": "grok",
      "model": "grok-3-thinking",
      "description": "xAI's step-by-step reasoning model - best for complex problems, but older",
      "quality_score": 93
    },
    {
      "platform": "groq_fast",
      "model": "llama-3.1-70b-versatile",
      "description": "Meta's large model via Groq - ultra-fast inference with decent quality",
      "quality_score": 85
    },
    {
      "platform": "claude",
      "model": "claude-4-opus-20250522",
      "description": "Anthropic's most powerful model - highest capability, but slow and sometimes errors",
      "quality_score": 95
    },
    {
      "platform": "perplexity",
      "model": "llama-3.1-sonar-large-128k-online",
      "description": "Perplexity's web-connected model - great for current information",
      "quality_score": 86
    },
    {
      "platform": "huggingface",
      "model": "meta-llama/Llama-3.3-70B-Instruct",
      "description": "Meta's latest open source model - excellent general capability",
      "quality_score": 84
    },
    {
      "platform": "deepseek",
      "model": "deepseek-reasoner",
      "description": "DeepSeek's reasoning specialist - best for complex logic",
      "quality_score": 88
    },
    {
      "platform": "openai",
      "model": "o4-mini",
      "description": "OpenAI's efficient reasoning model - fast and capable",
      "quality_score": 83
    },
    {
      "platform": "openai",
      "model": "gpt-4o-mini",
      "description": "OpenAI's lightweight multimodal model - good balance",
      "quality_score": 82
    },
    {
      "platform": "groq_fast",
      "model": "llama-3.1-8b-instant",
      "description": "Meta's small model via Groq - lightning fast responses",
      "quality_score": 78
    },
    {
      "platform": "grok",
      "model": "grok-3-mini",
      "description": "xAI's lightweight thinking model - efficient reasoning",
      "quality_score": 80
    },
    {
      "platform": "perplexity",
      "model": "llama-3.1-sonar-small-128k-online",
      "description": "Perplexity's fast web-connected model",
      "quality_score": 79
    },
    {
      "platform": "groq_fast",
      "model": "mixtral-8x7b-32768",
      "description": "Mistral's mixture of experts via Groq - specialized performance",
      "quality_score": 81
    },
    {
      "platform": "groq_fast",
      "model": "gemma2-9b-it",
      "description": "Google's Gemma model via Groq - efficient and fast",
      "quality_score": 77
    },
    {
      "platform": "grok",
      "model": "grok-2",
      "description": "xAI's previous generation - still very capable",
      "quality_score": 76
    },
    {
      "platform": "claude",
      "model": "claude-3-7-sonnet-20250224",
      "description": "Anthropic's stable previous generation",
      "quality_score": 74
    },
    {
      "platform": "perplexity",
      "model": "llama-3.1-sonar-large-128k-chat",
      "description": "Perplexity's offline chat model - no web search",
      "quality_score": 73
    },
    {
      "platform": "huggingface",
      "model": "meta-llama/Llama-3.1-70B-Instruct",
      "description": "Meta's previous large model - reliable performance",
      "quality_score": 72
    },
    {
      "platform": "huggingface",
      "model": "meta-llama/Llama-3.1-8B-Instruct",
      "description": "Meta's small efficient model - fast responses",
      "quality_score": 70
    },
    {
      "platform": "perplexity",
      "model": "llama-3.1-sonar-small-128k-chat",
      "description": "Perplexity's fast offline chat model",
      "quality_score": 69
    },
    {
      "platform": "claude",
      "model": "claude-3-5-sonnet-20241022",
      "description": "Anthropic's efficient lighter model",
      "quality_score": 71
    },
    {
      "platform": "grok",
      "model": "grok-beta",
      "description": "xAI's experimental features - cutting edge but unstable",
      "quality_score": 68
    },
    {
      "platform": "huggingface",
      "model": "mistralai/Mistral-7B-Instruct-v0.3",
      "description": "Mistral's efficient European model",
      "quality_score": 67
    },
    {
      "platform": "huggingface",
      "model": "Qwen/Qwen2.5-7B-Instruct",
      "description": "Alibaba's latest efficient model",
      "quality_score": 66
    },
    {
      "platform": "ollama",
      "model": "llama3.2",
      "description": "Local Meta model - privacy focused",
      "quality_score": 65
    }
  ],
  "fallback_order": [
    "gemini",
    "openai", 
    "grok",
    "openrouter",
    "claude",
    "deepseek",
    "groq_fast",
    "perplexity",
    "huggingface",
    "ollama",
    "ai21",
    "stability",
    "fireworks",
    "anyscale",
    "mistral",
    "together",
    "cohere",
    "replicate"
  ],
  "personality_defaults": {
    "honest": {
      "preferred_models": ["grok-4", "gpt-4.1", "gemini-2.5-flash", "grok-3", "claude-4-sonnet-20250514", "deepseek-chat"],
      "reason": "These models tend to be more direct and factual"
    },
    "friend": {
      "preferred_models": ["grok-4", "claude-4-sonnet-20250514", "gemini-2.5-flash", "gpt-4.1"],
      "reason": "These models are better at emotional and supportive responses"
    },
    "coach": {
      "preferred_models": ["grok-4", "gpt-4.1", "gemini-2.5-flash", "claude-4-opus-20250522", "grok-3"],
      "reason": "These models excel at motivational and goal-oriented responses"
    },
    "wise": {
      "preferred_models": ["grok-4", "claude-4-opus-20250522", "gemini-2.5-pro", "gemini-2.5-flash", "gpt-4.1"],
      "reason": "These models provide the most thoughtful and philosophical responses"
    },
    "creative": {
      "preferred_models": ["grok-4", "gpt-4o", "gpt-4.1", "gemini-2.5-flash", "claude-4-sonnet-20250514"],
      "reason": "These models are most innovative and artistic in their responses"
    }
  }
}
